\chapter{Background}

This chapter provides background information that helps to understand the
thesis. We first revisit the rise of asm.js and its toolchain, Emscripten,
followed by an introduction to WebAssembly and its standardized
\emph{WebAssembly System Interface} (WASI). Finally, we will give a brief
overview of the LLVM compilation framework.

\section{Emscripten and Asm.js}

In the past decade, web-based applications are gaining popularity, and due to
the design of most browsers, programmers tend to choose JavaScript or its
dialects to implement them. One natural problem is how to compile programs that
target the native platform to run over the internet. Making the situation more
challenging, programs with a large codebase, for example games that require
complex video and physical computation, are nearly impossible to translate
line-by-line manually. In 2010, Alon Zakai started the first attempt at
translating source code that targets native platforms into JavaScript
\cite{8118483}. After two years of development, he published Emscripten that
translates LLVM intermediate representation into asm.js, a JavaScript subset
\cite{10.1145/2048147.2048224}. An asm.js program shares a similar programming
model to that which one would expect on the native platform. The detailed asm.js
specification is available on the official website
\footnote{asm.js specification: \url{http://asmjs.org/spec/latest/}}.
We will visit several critical features in asm.js with examples in
figure~\ref{fig:adler-32} (page~\pageref{fig:adler-32}). These examples are
implementations of the Adler-32 hashing algorithm used in ZLib compression
library \cite{adler32-paper} \footnote{Revisiting Fletcher and Adler Checksums:
  \\\url{http://www.zlib.net/maxino06\_fletcher-adler.pdf}}, in both C and its
corresponding generated asm.js with Emscripten.

\begin{figure}
  \centering
  \begin{subfigure}{\textwidth}
    \lstinputlisting[
      language=C,
      basicstyle=\linespread{0.4}\small\ttfamily, numbers=left
    ]{Code/adler32.c}
    \caption{C}
    \label{fig:adler-32-c}
  \end{subfigure}
  \begin{subfigure}{\textwidth}
    \lstinputlisting[
      language=JavaScript,
      basicstyle=\linespread{0.4}\small\ttfamily, numbers=left
    ]{Code/adler32.js}
    \caption{asm.js}
    \label{fig:adler-32-asmjs}
  \end{subfigure}
  \begin{subfigure}{\textwidth}
    \lstinputlisting[
      basicstyle=\linespread{0.4}\small\ttfamily,
      numbers=left
    ]{Code/adler32.wat}
    \caption{Text-format WebAssembly}
    \label{fig:adler-32-webassembly}
  \end{subfigure}
  \caption{Adler 32 in C, asm.js and text-format WebAssembly}
  \label{fig:adler-32}
\end{figure}

\paragraph{Function prologue and type annotation}
JavaScript is a dynamically typed language. Hence, a proper implementation needs
to verify the types of variables when needed. Although several optimization
techniques can eliminate some of the checks and improve the execution
performance, such language features can still incur a significant performance
loss. Asm.js adds type annotations to function parameters and expressions to
address this problem. In figure~\ref{fig:adler-32-asmjs}, Emscripten generates
parameter annotations for parameters \texttt{\$0\_1} and \texttt{\$0\_2} at
line $2$ and line $3$ respectively. The trailing bitwise `or' operation against
zero hints that both arguments are integral values since bitwise operations are
only defined for integral values in JavaScript. Emscripten also annotates
float-point numbers with the unary positive operation, `+', which we do not show
in the example. A system that supports asm.js directly can quickly recover the
type information from the annotations, which, in theory, can improve both the
compilation and execution performance. On the other hand, for a system that does
not recognize asm.js, the program above is still a valid JavaScript program, and
the type annotations ensure the correct semantics for numeric operations.

\paragraph{Control flow}
LLVM employs a register-based intermediate representation with a
\emph{control flow graph} (CFG). However, JavaScript uses structured control
flow and does not allow arbitrary jump statements similar to one would expect
in C. Hence, when translating LLVM IR to asm.js, Emscripten mimics the branch
instructions between basic blocks in the generated code with JavaScript
control-flow statements. Emscripten uses a pattern-based translation and
classifies control flow changes into three categories.
In figure~\ref{fig:adler-32-asmjs}, we demonstrate two of the three
control-flow structures, \emph{if} and \emph{loop}, at line $6$ and line $7$
respectively. Asm.js also has a third control flow structure, \emph{block},
which we do not show in the example. A \emph{block} structure is similar to a
\emph{loop} structure and can be translated to a while loop with an always-false
condition. A branch instruction referring to the \emph{block} is equivalent
to a break statement in this case. WebAssembly adopts a similar design, and we
will revisit this in the later section with more details.

\paragraph{Byte array as heap}
Emscripten uses multiple typed array views that share a single underlying byte
array buffer to simulate the heap in a native programming model.
In figure~\ref{fig:adler-32-asmjs}, the asm.js example uses \texttt{HEAPU8}, an
unsigned byte view over the byte array at line $8$, to access the data passed by
the pointer via the first argument. Asm.js also offers other array views such
as \texttt{HEAPI32} and \texttt{HEAPF32} which allows programs to access 32-bit
signed integers and single-precision floating-point numbers on the heap. This
technique also inspires the linear memory design in WebAssembly, which we will
discuss later in the chapter with more details.

Emscripten is quite successful. Experiment results show that it can port most of
the C/C++ programs of non-trivial code size to the web with approximately
50-67\% of native performance
\footnote{Alon Zakai's presentation on Emscripten at CppCon:
  \\\url{https://kripken.github.io/mloc_emscripten_talk/cppcon.html}}
without any missing significant features.

\section{WebAssembly}

Although Emscripten with asm.js is successful, there are still several problems
that remain unaddressed. One of them is the parsing overhead. As asm.js is a
strict subset of JavaScript, parsing the generated program is a non-trivial task
due to the complexity of JavaScript grammar. Additionally, because Emscripten
emits generated programs in asm.js, the output size grows significantly faster
than the native binary. Another problem regards the generated programs' safety,
especially when running an untrusted module received over the internet. In 2017,
the WebAssembly community established and proposed a new standard for
distributing programs over the internet to address these problems. The design of
WebAssembly focuses on safety, performance, portability, and compactness. The
introduction paper describes the detailed structure, validation rules
\cite{10.1145/3167082}, and execution semantics of WebAssembly
\cite{10.1145/3062341.3062363}. Here we will only visit some of the key points
that help understand the rest of the thesis. In
figure~\ref{fig:adler-32-webassembly} we also present a simple WebAssembly
program that implements the Adler32 hashing.

\paragraph{Module structure}
WebAssembly modules can have four different kinds of entities: \emph{functions},
\emph{indirect tables}, \emph{linear memories}, and \emph{globals}. Modules are
also able to import and export entities by names. In
figure~\ref{fig:adler-32-webassembly}, we define a \emph{function} and a
\emph{linear memory} and export them under name \texttt{adler32} and
\texttt{memory} respectively. WebAssembly functions can define an arbitrary
number of local variables and possibly an empty sequence of instructions as the
body. All instruction operates over an implicitly declared stack. The
control-flow will return from the function by either a \texttt{return}
instruction or reaching the end of the body. WebAssembly linear memories have
bounds consisting of a pair of integers, representing the lower bound and upper
bound respectively, \footnote{The upper bound is optional} in units of $16$-KiB
pages. In figure~\ref{fig:adler-32-webassembly}, at line $21$, we defined a
linear memory with a minimal size of $32$-KiB. WebAssembly linear memory can
also associate with zero or multiple \emph{data} segments. Each \emph{data}
segment contains a constant evaluated expression, representing the
initialization offset, and a sequence of bytes that the runtime environment will
copy from. WebAssembly indirect tables are similar to linear memories, but they
store function pointers instead of bytes. A \emph{indirect table} has a type
that consists of an upper and lower bound similar to \emph{linear memory}, as
well as a function type indicating the type of the function pointers allowed
\footnote{Currently, the function type must be \texttt{funcref} which is a union
  type of all possible function types.}. WebAssembly tables also introduce their
initializer, \emph{element} segments. The \emph{element} segment is similar to
the \emph{data} segment, but it initializes function pointers instead of bytes.
Another difference between linear memories and indirect tables is that indirect
tables are immutable after initialization to ensure the module's safety
\footnote{This is subject to change in the reference type extension}.

\paragraph{Linear memory}
Similar to asm.js, WebAssembly programs can access one or multiple
\emph{linear memories} \footnote{In the current version of WebAssembly, at most
  one linear memory is allowed within a single module}. The memory is unmanaged,
and it is the program's responsibility to handle the layout correctly. The
program can grow the \emph{linear memory} if needed via the \texttt{memory.grow}
instruction; however, the runtime environment is not obligated to increase the
\emph{linear memory}. The program can check the result of the command via the
instruction's return value. Asm.js also allows the growth of the heap byte
array. However, due to the limitations of JavaScript, this operation is usually
quite expensive, as there is no efficient \texttt{realloc} algorithm provided in
JavaScript, and it requires allocating a byte array with a larger capacity and
copying byte-by-byte. WebAssembly specification does not impose requirements on
the time complexity of growing the linear memory, yet it encourages any
implementation to avoid copying.  Unlike native heap memory, there is no
alignment requirement on load-store instructions; i.e., load-store can start at
any byte in the memory with the probable additional cost for unaligned access.
However, there are boundary checks applied to the linear memory. Any
out-of-bound access will result in a runtime panic. Additionally, WebAssembly
specification requires any runtime environment implementation to
zero-initialize the linear memory.

\paragraph{Indirect table}
Asm.js represents function pointers using first-class function values, thanks to
JavaScript. However, in WebAssembly, every entity is referred to with indices
representing references, and value types only consist of integral types and
floating-point types \footnote{WebAssembly may introduce more primitive value
  types in the future.}. Hence, we need something creative to implement the
function pointers in WebAssembly. The solution utilizes one special instruction
\texttt{call\_indirect} and indirect tables. During module initialization, the
runtime environment will initialize the indirect table according to the
\emph{element} section. Each \texttt{call\_indirect} instruction associates
with an index and an expecting type. The runtime environment will perform both
a validity check on the index and a type check with the expecting type's help.
Unlike the linear memory, the indirect table is not growable at runtime and
currently is immutable once the initialization phase is complete. An indirect
table does not limit the function pointers stored to be internal functions nor
even WebAssembly functions. The function pointer can even be a host native
function; many runtime environment implementations utilize this feature to
register native call-back functions to WebAssembly modules.

\paragraph{Structured control flow}
Another WebAssembly's key feature is the structured control structure. Unlike
the native binary and most of the bytecode representations that utilize labels
and offsets, WebAssembly has structured control flow instructions and classifies
them into three categories, \emph{block}, \emph{if} and \emph{loop}, similar to
asm.js. Each control flow instruction can optionally associate with a value
type, representing the change on the operand stack once the control block exits
\footnote{WebAssembly multivalue extension relaxes the requirement and allows
  structured control instruction to have a function type. If a control
  instruction associate with a function type, the parameter types refer to the
  value consumed from the operand stack and result types refer to the value
  added to the operand stack.}. A \emph{block} control flow is perhaps the
simplest structure. It introduces a label index to the context. The label is
only referable within the \emph{block} construct by indices. If a branch
instruction refers to the block's label, the runtime environment will redirect
the control flow as if it reaches the \emph{block}'s end. An \emph{if} control
flow is similar to the \emph{block} control flow with two significant
differences. One is that it will implicitly consume a 32-bit integer from the
stack and choose the branch accordingly. The other difference is that it can
optionally have a \emph{false} branch. If the \emph{false} branch is missing,
the runtime environment will redirect the control flow to reach the {if}'s end,
similar to the \emph{block} control flow structure. The last control flow
structure is \emph{loop}. The only difference between the \emph{loop} control
structure and \emph{block} structure is when a branch instruction refers to it.
When a branch instruction refers to a \emph{loop} block, the runtime environment
will redirect the control flow to the \emph{loop}'s beginning instead of the
end. In the figure \ref{fig:adler-32-webassembly}, we present the \emph{if}
structure on line $5$, and \emph{loop} structure on line $7$. The example does
not contain a \emph{block} structure, but there is no difference between it and
a \emph{loop} structure at the syntax level.

Generally speaking, WebAssembly's performance, compared to its native
counterpart, varies significantly from test case to test case. On the browser
side, WebAssembly can finish most test cases within $10\%$ slower than the
native version and all test cases within two times slower
\cite{10.1145/3062341.3062363}. Another test shows similar results for most
test cases, except one case is 2 times to $3.4$ times slower than native,
depending on the input size \cite{234914}. For generated code size, the
community introduction paper claims $85.3\%$ compare to native implementations.
WebAssembly is not only successful in the field of Web-based applications. It
also defines a portable format for distributing programs over the internet,
similar to what we have seen in Java and its virtual machine. GraalVM now has
its interpreter for WebAssembly modules, TruffleWasm \cite{trufflewasm}, and can
execute WebAssembly modules with impressive performance with only $4\%$ slower
than WebAssembly reference implementation in most of the cases, and even $4\%$
faster in PolybenchC.

\section{WebAssembly Extensions}

In the previous section, we presented the core part of WebAssembly published by
the community in late 2016 as a minimal viable product (MVP). Although the
WebAssembly MVP is powerful enough to host most of the applications
\cite{webassembly-survey}, there still exists room for improvement. These
post-MVP proposals enhance the functionality of WebAssembly by introducing new
instructions or modifying existing module constructs. For example, MVP
WebAssembly has no support for exception handling. Thus, when compiling programs
implemented in C++, users need to explicitly turn off the compiler's exception
feature. The exception handling post-MVP extension addresses the
problem by introducing a special \texttt{try} block which enables user-defined
stack unwinding. Most post-MVP extensions are still in the early stage of
development and may merge into core WebAssembly in the future. This project
implemented several post-MVP features such as integral value sign extension,
non-trapping floating-point conversion, multivalue semantics, and fixed-width
SIMD vector operation. In this section, we will quickly visit these post-MVP
feature extensions.

\paragraph{Integral value sign extension}
MVP WebAssembly only has 32-bit and 64-bit integral values. However, many
programming languages support integers with a smaller width. Thus, implementing
short integral values in WebAssembly is quite awkward. To alleviate the problem,
MVP WebAssembly has instructions that can perform load and store of 8-bit and
16-bit integers with signed or zero extension semantics. However, what if one
already has a short integer on the stack and would like to perform a sign
extension?  Unfortunately, there are no immediate solutions. One possible
work-around is to store the value to the linear memory and then sign extend with
the load instruction's help, which is quite expensive. The sign extension
proposal introduces new instructions that perform the sign extension for stack
values. For example, \texttt{i32.extend8\_s} consumes a 32-bit integer from the
stack then performs the sign extension to 32-bit integer operand as if the
operand is an 8-bit integer. The proposal also introduces similar instructions
for 64-bit integers.

\paragraph{Non-trapping float-to-int conversion}
MVP WebAssembly offers floating-point-to-integer conversion with implicit range
checks to fulfill the no-undefined behaviour design goal of the language. If the
desired integer type cannot accurately represent the floating-point value, the
runtime environment should trap. However, in most other languages, such as LLVM,
the conversion yields an undefined result without trapping in such scenarios.
Thus, if one wants to faithfully simulate the conversion between floating-point
and integers, an \texttt{if} block with manual checks is usually required. This
proposal introduces saturated conversion to address the problem. If the desired
integer type cannot represent the resulting number, the instruction employs
saturated semantics. More specifically, if the floating-point value is more
significant than the maximum representable value of the integer type, the
maximum value is returned, and the same holds in the case of value underflow.
This extension also lays the foundation of SIMD vector operations to achieve
more hardware-like semantics, which we will see later in this section.

\paragraph{Multivalue}
The multivalue proposal focuses on two aspects of WebAssembly, the function
return value and the types of structured-control-flow constructs. In MVP
WebAssembly, the function can have at most one return value. The proposal
generalizes the function type by allowing functions to return multiple return
values. For structured-control-flow constructs, MVP WebAssembly requires that
any instructions within the construct cannot consume stack values outside of the
stack frame. Additionally, the construct can put at most one value
onto the stack when it exists. One advantage of having such strict rules on
structured-control-flow constructs is that the validation rule is trivial, and
the runtime system can compute the stack height with minimal effort. However,
this has its drawbacks. For example, this method causes the bloat of local
variables. When entering a structured-control-flow construct, the program needs
to push all the values it may need to the local variables, then load them back
to the stack later, which is quite expensive. The multivalue proposal relaxes
such constraints by allowing the control-flow-construct to have a function type.
Function types' parameter types indicating the type of values that the construct
will consume, and the result types hint at the type of values that will be
pushed onto the stack.

\paragraph{SIMD vector operations}
Single-instruction-multiple-data (SIMD) is a powerful tool for implementing
high-performance programs. Many modern compilers, such as GCC, have
auto-vectorization analysis and transformation to automatically rewrite scalar
codes in parallel form \cite{auto-vec-gcc}. Before WebAssembly, many attempts
have been made to implement SIMD operations over the internet, most notably,
SIMD.js \footnote{\url{https://hacks.mozilla.org/2014/10/introducing-simd-js/}}.
The design of the SIMD vector operation proposal is based on the design of
SIMD.js. Currently, the proposal focuses on 128-bit vector operation, which is
widely available on different hardware architectures such as SSE
\cite{sse-intel}, and ARM Neon \cite{arm-neon}. The proposal introduces a new
value type \texttt{v128} representing a 128-bit vector. Note that the vector
type does not contain any knowledge about the element type and how to interpret
the lane, which is the number and the type of elements packed into a single
vector, depends on the instruction. The SIMD vector operations proposal takes
instructions from the intersection among different hardware architectures to
ensure the module's portability. For example, \texttt{i32x4.add} will interpret
both operands as packed 32-bit integers and perform lane-wise addition between
them, while \texttt{f64x2.sqrt} will interpret its operand as a packed
double-precision floating-point numbers. Most of the instructions are a direct
generalization of the scalar operations in MVP WebAssembly. One notable
difference is the floating-point conversion semantics. In MVP WebAssembly, the
conversion will trap in the case of overflow or underflow. In contrast, in the
SIMD vector proposal, packed floating-point value conversions follow similar
semantics to those defined in the non-trapping float-to-int conversion proposal.

\section{WebAssembly System Interface (WASI)}

In the previous section, we introduce WebAssembly as a new format for delivering
programs over the internet. Question then arises: can we push WebAssembly beyond
the browser? On the other hand, if we want to compile the native program into
WebAssembly, how do we translate operating-system-specific commands, such as
file access? Taking a step further, how do we ensure the safety of the generated
program? In the early days of development, Emscripten generates JavaScript glue
code that mimics the operating system syscalls. However, this ad-hoc solution
results in messy and nonportable code.

To address these problems, the WebAssembly community started the process of
standardizing the system interface for modules
\footnote{WASI initial announcement: \\\url{https://hacks.mozilla.org/2019/03/
    standardizing-wasi-a-webassembly-system-interface/}}. The WASI interface
design focuses on two aspects, portability and safety, following the WebAssembly
design philosophy. The interface is still under active development at the time
of thesis writing. In this project, we implement the interface functions only
if they are needed while designing the backend library to be extensible. The
official API documentation provides a detailed view on the design of the
interface \footnote{WASI API documentation: \\\url{https://github.com/
    WebAssembly/WASI/blob/main/phases/snapshot/docs.md}}.
Figure~\ref{fig:wasi-intro} gives a general illustration of the relationship
among the WebAssembly module, the runtime environment, and WASI. Here we will
focus on several key points of the design that will help understanding the
thesis.

\begin{figure}
  \centering
  \includegraphics{Images/wasi-intro.pdf}
  \caption{A illustration of WASI}
  \label{fig:wasi-intro}
\end{figure}

\paragraph{WASI ABI model}
WASI classifies modules into two categories, \emph{commands} and
\emph{reactors}. A \emph{command} module has a single entry function, namely
\texttt{\_start} and all the other exported functions are hide from the user.
On the other hand, a \emph{reactor} module has an optional initialization
function named \texttt{\_initialize}. If such initialization function is
present, the runtime environment is obligated to invoke such a function before
calling others. The runtime environment may invoke either the start or
initializer function once during a module's lifetime. Additionally, every
WASI-compatible model needs to export a linear memory under the name
\texttt{\_memory}, and all addresses referred by modules are offsets within
this linear memory. Similarly, modules will also export an indirect table
under the name \texttt{\_\_indirect\_function\_table}. The runtime environment
will pass function pointers through the indirect table. Additionally, WASI
requires the runtime environment to provide all WASI API under module name
\texttt{wasi\_snapshot\_preview1} \footnote{This will change in the future, as
  WASI is still in the standardization phase.}.

\paragraph{Sandbox}
As we described above, WASI API follows WebAssembly's design philosophy, safety,
performance, portability, and compactness. WASI modules execute under a
capability-based security system to ensure the safety of the host environment.
The host runtime system will provide a sandboxed environment for each model. For
example, for file system access, WASI standard library C works with a virtual
file system for each module with the help of libpreopen \footnote{libpreopen:
  \url{https://github.com/musec/libpreopen}} \footnote{In the more recent
  version of WASI libc, libpreopen is no longer required.}.

\paragraph{Non-invasive and extensible}
In our discussion above, one may notice that a WASI-compatible module is also a
valid WebAssembly module on its own. WASI does not introduce new instructions
nor sections to the module; instead, it provides all additional functionalities
through imported external functions. The design of WASI is also highly
extensible and split into separate modules. Currently, the WASI working group
focuses on developing the core part that provides most of the POSIX interface,
but it may add additional features in the future.

\section{LLVM Compiler Infrastructure}

In the last section of this chapter, we would like to have a quick overview of
the compiler pipeline design and LLVM compilation framework. Designing a robust
and efficient compiler in terms of both generated code and compilation speed is
challenging. The LLVM compiler framework \cite{llvm-thesis} alleviates the
problem by introducing a standardized intermediate representation (IR) between
the compiler frontends and backends. Backend developers can target their
analysis and transformations on the IR instead of specializing in different
languages. On the other hand, frontend developers can translate the source
language into the IR and expect the backend to support multiple target platforms
with efficient code generation. Figure~\ref{fig:llvm-intro} illustrates the LLVM
compilation pipeline. In this project, we are more interested in the frontend of
the framework. The LLVM official documentation and tutorial provide full details
of their intermediate representation \footnote{LLVM Language Reference Manual:
  \url{https://llvm.org/docs/LangRef.html}}. Here we will only discuss several
major differences between LLVM IR and WebAssembly that help understand the
thesis. We also provide an implementation of Adler-32 hashing in LLVM IR
generated with Clang in figure~\ref{fig:adler-32-llvm}.

\begin{figure}
  \centering
  \includegraphics{Images/llvm-intro.pdf}
  \caption{A illustration of LLVM compilation pipeline}
  \label{fig:llvm-intro}
\end{figure}

\begin{figure}
  \centering
  \lstinputlisting[
    language=LLVM,
    basicstyle=\linespread{0.8}\small\ttfamily,
    numbers=left
  ]{Code/adler32.ll}
  \caption{Adler 32 in LLVM}
  \label{fig:adler-32-llvm}
\end{figure}

\paragraph{Register-based IR against stack-based IR}
In WebAssembly, all instructions operate over an implicitly declared stack. For
example, in figure~\ref{fig:adler-32-webassembly} at line $20$, a 32-bit integer
constant instruction, \texttt{i32.const}, will push the constant value on the
stack, and a 32-bit add instruction, \texttt{i32.add} will pop two values off
the stack as left-hand-side and right-hand-side operands accordingly, then push
the sum onto the stack. On the other hand, LLVM utilizes a register-based IR,
which is more similar to what one would expect on a native machine. In
figure~\ref{fig:adler-32-llvm}, each value for example, \texttt{\%0},
\texttt{\%1}, etc is a virtual register. Later in the backend, the register
allocation pass will map the virtual registers into physical registers using
register allocation algorithms.

\paragraph{Control flow, basic block, and $\phi$ instruction}
As we saw in previous sections, WebAssembly has specialized instructions to
manage the program's control flow. On the other hand, LLVM took a more
traditional approach to the problem. In 1991, researchers from IBM introduced
\emph{static single assignment} (SSA) form to ease the difficulty of writing
program analysis and transform passes \cite{ibm-ssa}. In SSA, each value has its
definition exactly once, and hence, the use-definition chain (UD chain) is
trivial to compute. The UD chain presents the relationship between variable
declarations and variable-uses in a graph. It helps the analysis pass to
efficiently pinpoint the information about variables and identify if the
variable declaration is necessary or not. However, in most of the programs,
these information needs to be merged from different control-flows; for example,
in a for-loop, the loop counter may be defined in the loop initialization and on
each loop iteration. The SSA introduces a special kind of instructions, $\phi$
instructions, which explicitly mark the merge of definitions from different
execution paths. LLVM adopts this design principle in its intermediate
representation. In figure~\ref{fig:adler-32-llvm} we have multiple $\phi$
instructions. For example, at line $11$ and $12$, value $\%7$ and $\%8$
represent $a$ and $b$ accordingly. We know that $a$ and $b$ initialized to
$0$ and $1$ upon entry and updated on each iteration from our C implementation.
In the generated LLVM IR, these merges induce $\phi$ instructions. For $a$
($\%7$), if the control flow is from the beginning of the function, we set its
value to $1$, and on the other hand, if the control flow is from the loop
iteration, we update its value accordingly. The different paths inducing a
$\phi$ instruction are indicated by basic block numbers. A basic block groups
the maximum number of instructions without control flow transfer. At line $11$,
we see the $\phi$ instruction merges the definition coming from the $\%2$
which is the entry block and $\%4$. Additionally, $\phi$ instructions must
appear before any other instructions within the same basic block, as they model
the merging of values and do not have any execution semantics.

\paragraph{Memory and load-store instruction}
The last significant difference between WebAssembly and LLVM IR is on the memory
and its related instructions. As we discussed earlier, a WebAssembly module can
have access to multiple linear memories \footnote{In the current version of
  WebAssembly, only one linear memory is allowed per module}. One might confuse
WebAssembly's linear memory with the concept of address space in LLVM IR. LLVM
IR associates each address with an integer value, namely, the address space.
However, unlike linear memory in WebAssembly, which has no difference between
one and another, the LLVM backend interprets the address space differently for
various architectures. For example, in the PTX backend, a backend target for
Nvidia GPUs, the implicit address space $0$ refers to traditional main RAM, and
address space $4$ represents the address shared by both main RAM and GPU RAM
\footnote{An introduction for PTX backend:
  \\\url{https://llvm.org/devmtg/2011-11/Holewinski_PTXBackend.pdf}}. For most
of the architecture, the implicit address space is the only address space
available to the programmer. Another difference between WebAssembly and LLVM IR
is on the design of load-store instructions. Load store instructions in both
languages have an attribute of alignment. However, LLVM IR interprets this
attribute differently from WebAssembly. In WebAssembly, the alignment attribute
acts as a hint to the runtime environment. If the alignment hint is unsuitable,
the runtime environment should still proceed under a possible penalty in the
performance. However, in LLVM IR, the alignment attribute is a requirement.
Any memory access that violates the alignment attribute will result in a
undefined behaviour, usually a runtime panic. A load-store instruction in LLVM
IR with alignment set to one will never fail. However, it will be significantly
less efficient as the backend will likely generate byte-wise load and
concatenation instructions.

We visited some of the background information that helps with understanding the
thesis in this chapter. In the next chapter, we will start from the beginning of
the system implementation, the WebAssembly parsing and validation frontend.